{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.035765Z",
     "start_time": "2025-12-21T18:11:19.024372Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch                          # Le cœur de PyTorch : tensors, calculs, GPU\n",
    "import torch.nn as nn                 # Contient toutes les couches du réseau (Conv2D, Linear, etc.)\n",
    "import torch.optim as optim           # Optimiseurs pour entraîner le modèle (Adam, SGD, etc.)\n",
    "from torch.utils.data import DataLoader  # Pour gérer le batching et le shuffle des datasets\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets, transforms, models  # Outils pour datasets, transformations et modèles pré-entraînés\n",
    "from torch import tensor\n",
    "\n",
    "import numpy as np                    # Manipulation de tableaux, conversion images → tensors\n",
    "import pandas as pd                   # Pour lire et écrire le fichier test_template.csv\n",
    "import os                             # Gestion des fichiers et dossiers\n",
    "\n",
    "# -----------------------------\n",
    "# Librairies pour la visualisation\n",
    "# -----------------------------\n",
    "import matplotlib.pyplot as plt       # Visualiser les images et tracer des courbes\n",
    "\n",
    "# -----------------------------\n",
    "# Librairies pour la vision par ordinateur\n",
    "# -----------------------------\n",
    "import cv2                            # Capturer la webcam et détecter les visages\n",
    "from PIL import Image \n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf8e8b82b9cec0fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.415221Z",
     "start_time": "2025-12-21T18:11:19.072187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'neutral')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions = ['neutral', 'angry', 'fear', 'happy', 'sad', 'surprise', 'disgust']\n",
    "emotion = 'neutral'\n",
    "x = random.randint(0, 6)\n",
    "path = f'data/dataTrain/train/{emotion}/'\n",
    "img = io.imread(os.path.join(path, random.choice(os.listdir(path))))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(emotion)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0c74cba097aa9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.532552Z",
     "start_time": "2025-12-21T18:11:19.433898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy : 7215\n",
      "sad : 4830\n",
      "fear : 4097\n",
      "surprise : 3171\n",
      "neutral : 4965\n",
      "angry : 3995\n",
      "disgust : 436\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for emotion in os.listdir('data/dataTrain/train'):\n",
    "    print(emotion, \":\", len(os.listdir(os.path.join('data/dataTrain/train', emotion))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8ee914af4626b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.760378Z",
     "start_time": "2025-12-21T18:11:19.653588Z"
    }
   },
   "outputs": [],
   "source": [
    "#Éviter le changement dans validation (on veut avoir les images réels)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    \n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomRotation(10),        # rotation ±10°\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),  # zoom léger\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225)\n",
    "    )\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"data/dataTrain/train\", transform=train_transform)\n",
    "val_data   = datasets.ImageFolder(\"data/dataTrain/train\", transform=val_transform)\n",
    "test_data  = datasets.ImageFolder(\"data/dataTest\", transform=val_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f799ac6eb5969f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.856250Z",
     "start_time": "2025-12-21T18:11:19.793274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split train / validation\n",
    "train_size = int(0.8 * len(train_data))\n",
    "validation_size = len(train_data) - train_size\n",
    "train_dataset, validation_dataset = random_split(train_data, [train_size, validation_size])\n",
    "\n",
    "# ⚠️ Remplacer le dataset de validation par celui sans augmentation\n",
    "validation_dataset.dataset = val_data\n",
    "\n",
    "# Créer les DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=128, shuffle=False)\n",
    "test_loader  = DataLoader(test_data, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aab4e647575f7bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:20.332715Z",
     "start_time": "2025-12-21T18:11:19.875120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=512, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/massylia/Desktop/HackatonCodeML-main/.venv/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/massylia/Desktop/HackatonCodeML-main/.venv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# --- Modèle : ResNet18 fine-tuning ---\n",
    "modeleEmotions = models.resnet18(pretrained=True)\n",
    "\n",
    "#degele aussi layer 3 (avant que 4) \n",
    "for name, param in modeleEmotions.named_parameters():\n",
    "    if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "nbEmotions = 7\n",
    "modeleEmotions.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(512, nbEmotions)\n",
    ")\n",
    "\n",
    "\n",
    "print(modeleEmotions) # Modèle de classification des émotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154f4b8c91daf5c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:25:20.794832Z",
     "start_time": "2025-12-21T18:25:20.701385Z"
    }
   },
   "outputs": [],
   "source": [
    "#loss function on ne veut pas geler toutes les couches. Sinon, le modele s'ameliore trop lentement\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "modeleEmotions = modeleEmotions.to(device)\n",
    "\n",
    "# --- Optimiseur:recopies / recoles la ligne de l’optimizer juste après avoir changé requires_grad.\n",
    "# (pour que l’optimizeur reconnaisse les nouvelles couches )---\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, modeleEmotions.parameters()),\n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "# Scheduler qui réduit le learning rate. eviter stagnation \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',          # surveille la val_loss\n",
    "    factor=0.5,          # réduit LR de moitié\n",
    "    patience=1,          # attend 1 epoch avant de réduire\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b327164ef180ec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:25:27.575737Z",
     "start_time": "2025-12-21T18:25:22.846111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs shape: torch.Size([128, 7])\n",
      "labels shape: torch.Size([128])\n",
      "labels dtype: torch.int64\n",
      "labels min/max: 0 6\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "images, labels = next(iter(train_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "outputs = modeleEmotions(images)\n",
    "print(\"outputs shape:\", outputs.shape)   # doit être (64, 7) ou (dernier batch, 7)\n",
    "print(\"labels shape:\", labels.shape)     # doit être (64,) ou (dernier batch,)\n",
    "print(\"labels dtype:\", labels.dtype)     # doit être torch.int64 (Long)\n",
    "print(\"labels min/max:\", labels.min().item(), labels.max().item())  # doit être 0..6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529154f831b8c8a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T21:44:18.751042Z",
     "start_time": "2025-12-21T19:00:15.533475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train loss 1.4071 acc 0.4650 | Val loss 1.0910 acc 0.5918\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# --- Boucle principale ---\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     train_loss, train_acc = \u001b[43mrun_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodeleEmotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     val_loss, val_acc = run_one_epoch(modeleEmotions, validation_loader, training=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m acc \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     43\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVal loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m acc \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mrun_one_epoch\u001b[39m\u001b[34m(model, loader, training)\u001b[39m\n\u001b[32m     25\u001b[39m     loss.backward()\n\u001b[32m     26\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * images.size(\u001b[32m0\u001b[39m)\n\u001b[32m     29\u001b[39m preds = outputs.argmax(dim=\u001b[32m1\u001b[39m)\n\u001b[32m     30\u001b[39m correct += (preds == labels).sum().item()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "def run_one_epoch(model, loader, training: bool):\n",
    "    if training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.set_grad_enabled(training):\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            if training:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)              # (batch, nbEmotions)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if training:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "# --- Boucle principale ---\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = run_one_epoch(modeleEmotions, train_loader, training=True)\n",
    "    val_loss, val_acc = run_one_epoch(modeleEmotions, validation_loader, training=False)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train loss {train_loss:.4f} acc {train_acc:.4f} | \"\n",
    "          f\"Val loss {val_loss:.4f} acc {val_acc:.4f}\")\n",
    "\n",
    "scheduler.step(val_loss) #éviter stagnation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
