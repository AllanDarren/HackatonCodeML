{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T20:51:57.719236300Z",
     "start_time": "2025-12-23T20:51:57.702979700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch                          # Le cœur de PyTorch : tensors, calculs, GPU\n",
    "import torch.nn as nn                 # Contient toutes les couches du réseau (Conv2D, Linear, etc.)\n",
    "import torch.optim as optim           # Optimiseurs pour entraîner le modèle (Adam, SGD, etc.)\n",
    "from torch.utils.data import DataLoader  # Pour gérer le batching et le shuffle des datasets\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets, transforms, models  # Outils pour datasets, transformations et modèles pré-entraînés\n",
    "\n",
    "\n",
    "import numpy as np                    # Manipulation de tableaux, conversion images → tensors\n",
    "import pandas as pd                   # Pour lire et écrire le fichier test_template.csv\n",
    "import os                             # Gestion des fichiers et dossiers\n",
    "\n",
    "# -----------------------------\n",
    "# Librairies pour la visualisation\n",
    "# -----------------------------\n",
    "import matplotlib.pyplot as plt       # Visualiser les images et tracer des courbes\n",
    "\n",
    "# -----------------------------\n",
    "# Librairies pour la vision par ordinateur\n",
    "# -----------------------------\n",
    "import cv2                            # Capturer la webcam et détecter les visages\n",
    "from PIL import Image \n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random"
   ],
   "id": "aeb6b9ecbc34dcd5",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T20:51:57.806695900Z",
     "start_time": "2025-12-23T20:51:57.722263200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#observations des images\n",
    "emotions = ['neutral', 'angry', 'fear', 'happy', 'sad', 'surprise', 'disgust']\n",
    "emotion = 'neutral'\n",
    "x = random.randint(0, 6)\n",
    "path = f'data/dataTrain/train/{emotion}/'\n",
    "img = io.imread(os.path.join(path, random.choice(os.listdir(path))))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(emotion)\n",
    "# plt.show()"
   ],
   "id": "7514b82e2992d93f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'neutral')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T20:51:57.850670400Z",
     "start_time": "2025-12-23T20:51:57.807701400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "for emotion in os.listdir('data/dataTrain/train'):\n",
    "    print(emotion, \":\", len(os.listdir(os.path.join('data/dataTrain/train', emotion))))\n"
   ],
   "id": "e36a18a5ab11cb4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry : 3995\n",
      "disgust : 436\n",
      "fear : 4097\n",
      "happy : 7215\n",
      "neutral : 4965\n",
      "sad : 4830\n",
      "surprise : 3171\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T20:51:57.941308100Z",
     "start_time": "2025-12-23T20:51:57.851701900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels = 3), # images en niveaux de gris rgb\n",
    "    transforms.Resize((224, 224)),\n",
    "\n",
    "# data augmentation. eviter apprendre par coeur (chaque epoch change les images pour paraitre différement pour le modele)\n",
    "    transforms.RandomHorizontalFlip(),           # augmentation horizontale\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "\n",
    "    transforms.ToTensor(),             # convertit en tenseur [0,1]\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225)) # normalise entre des range que imagenet comprend bien\n",
    "])\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels = 3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225))\n",
    "])\n"
   ],
   "id": "37ff90f6fdca3e4e",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T20:51:57.964651900Z",
     "start_time": "2025-12-23T20:51:57.942460700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#80% des données d'entrainement pour l'entrainement et 20% pour validation\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "train_root = \"data/dataTrain/train\"\n",
    "\n",
    "# dataset \"base\" juste pour récupérer les labels (targets)\n",
    "base_ds = datasets.ImageFolder(train_root, transform=None)\n",
    "y = base_ds.targets  # liste d'entiers 0..6\n",
    "\n",
    "# séparation équilibré entre train et val\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(sss.split(X=[0]*len(y), y=y))\n",
    "\n",
    "# datasets avec les bons transforms\n",
    "train_full = datasets.ImageFolder(train_root, transform=train_transform)\n",
    "val_full   = datasets.ImageFolder(train_root, transform=eval_transform)\n",
    "\n",
    "train_dataset = Subset(train_full, train_idx)\n",
    "val_dataset   = Subset(val_full, val_idx)\n",
    "\n",
    "print(\"Train size:\", len(train_dataset), \"Val size:\", len(val_dataset))"
   ],
   "id": "e4e50d7a759bb228",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22967 5742\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# compter les classes dans le train split\n",
    "train_targets = [y[i] for i in train_idx]  # labels du train\n",
    "\n",
    "#compte le nombre d'images par class\n",
    "class_counts = torch.bincount(torch.tensor(train_targets))\n",
    "class_weights = 1.0 / class_counts.float() #attribut une proba a chaque class\n",
    "\n",
    "# poids par exemple (chaque image reçoit le poids de sa classe)\n",
    "sample_weights = torch.tensor([class_weights[t] for t in train_targets], dtype=torch.float)\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True #autorise de réutiliser des images\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, sampler=sampler, num_workers=2, pin_memory=True)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_data, batch_size=128, shuffle=False)"
   ],
   "id": "13a67a1fc4cf2655"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T20:51:58.098248900Z",
     "start_time": "2025-12-23T20:51:57.969176600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Modèle : ResNet18 fine-tuning ---\n",
    "modeleEmotions = models.resnet18(pretrained=True)\n",
    "\n",
    "# Dé-geler uniquement le dernier bloc convolutionnel + fc\n",
    "for name, param in modeleEmotions.named_parameters():\n",
    "    if \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "nbEmotions = 7\n",
    "modeleEmotions.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(512, nbEmotions)\n",
    ")\n",
    "\n",
    "\n",
    "print(modeleEmotions) # Modèle de classification des émotions\n"
   ],
   "id": "805228ee506d7176",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=512, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamta\\PycharmProjects\\PythonProject\\HackatonCodeML\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kamta\\PycharmProjects\\PythonProject\\HackatonCodeML\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T20:51:58.170006500Z",
     "start_time": "2025-12-23T20:51:58.099262200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#loss function on ne veut pas geler toutes les couches. Sinon, le modele s'ameliore trop lentement\n",
    "def get_device():\n",
    "    # NVIDIA GPU (Windows/Linux, parfois Mac via eGPU mais rare)\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    # Apple Silicon (Mac M1/M2/M3)\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    # Fallback\n",
    "    return torch.device(\"cpu\")\n",
    "print(torch.__version__)\n",
    "device = get_device()\n",
    "print(\"Using device:\", device)\n",
    "modeleEmotions = modeleEmotions.to(device)\n",
    "\n",
    "# --- Optimiseur et scheduler ---\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, modeleEmotions.parameters()),\n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "# Scheduler qui réduit le learning rate. eviter stagnation\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',          # surveille la val_loss\n",
    "    factor=0.5,          # réduit LR de moitié\n",
    "    patience=1,          # attend 1 epoch avant de réduire\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "2a63d1f1a27beeae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T20:51:58.805909200Z",
     "start_time": "2025-12-23T20:51:58.172122800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#sanity check\n",
    "images, labels = next(iter(train_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "outputs = modeleEmotions(images)\n",
    "print(\"outputs shape:\", outputs.shape)\n",
    "print(\"labels shape:\", labels.shape)\n",
    "print(\"labels dtype:\", labels.dtype)\n",
    "print(\"labels min/max:\", labels.min().item(), labels.max().item())  # doit être 0..6"
   ],
   "id": "4fd40c5040dab02b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs shape: torch.Size([128, 7])\n",
      "labels shape: torch.Size([128])\n",
      "labels dtype: torch.int64\n",
      "labels min/max: 0 6\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T21:27:41.549036900Z",
     "start_time": "2025-12-23T20:51:58.849716800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 20 # 20 epoch de base pour chaque modification\n",
    "\n",
    "#fonction principace d'entraiment et de validation\n",
    "def run_one_epoch(model, loader, training: bool):\n",
    "    if training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.set_grad_enabled(training):\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            if training:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)              # (batch, nbEmotions)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if training:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "# --- Boucle principale ---\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = run_one_epoch(modeleEmotions, train_loader, training=True)\n",
    "    val_loss, val_acc = run_one_epoch(modeleEmotions, validation_loader, training=False)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train loss {train_loss:.4f} acc {train_acc:.4f} | \"\n",
    "          f\"Val loss {val_loss:.4f} acc {val_acc:.4f}\")\n",
    "\n"
   ],
   "id": "a10c848ec8acb4c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train loss 1.4476 acc 0.4527 | Val loss 1.1618 acc 0.5618\n",
      "Epoch 2/20 | Train loss 1.1300 acc 0.5763 | Val loss 1.0817 acc 0.5928\n",
      "Epoch 3/20 | Train loss 0.9980 acc 0.6298 | Val loss 1.0751 acc 0.6055\n",
      "Epoch 4/20 | Train loss 0.8702 acc 0.6807 | Val loss 1.0659 acc 0.6127\n",
      "Epoch 5/20 | Train loss 0.7525 acc 0.7254 | Val loss 1.0856 acc 0.6115\n",
      "Epoch 6/20 | Train loss 0.6311 acc 0.7752 | Val loss 1.1272 acc 0.6163\n",
      "Epoch 7/20 | Train loss 0.5245 acc 0.8152 | Val loss 1.1313 acc 0.6127\n",
      "Epoch 8/20 | Train loss 0.4169 acc 0.8593 | Val loss 1.2375 acc 0.6183\n",
      "Epoch 9/20 | Train loss 0.3297 acc 0.8915 | Val loss 1.2825 acc 0.6115\n",
      "Epoch 10/20 | Train loss 0.2731 acc 0.9104 | Val loss 1.3261 acc 0.6129\n",
      "Epoch 11/20 | Train loss 0.2177 acc 0.9310 | Val loss 1.3157 acc 0.6200\n",
      "Epoch 12/20 | Train loss 0.1771 acc 0.9454 | Val loss 1.4174 acc 0.6170\n",
      "Epoch 13/20 | Train loss 0.1516 acc 0.9532 | Val loss 1.4685 acc 0.6092\n",
      "Epoch 14/20 | Train loss 0.1268 acc 0.9624 | Val loss 1.5119 acc 0.6104\n",
      "Epoch 15/20 | Train loss 0.1049 acc 0.9693 | Val loss 1.5639 acc 0.6139\n",
      "Epoch 16/20 | Train loss 0.0933 acc 0.9735 | Val loss 1.5830 acc 0.6090\n",
      "Epoch 17/20 | Train loss 0.0871 acc 0.9752 | Val loss 1.5824 acc 0.6205\n",
      "Epoch 18/20 | Train loss 0.0787 acc 0.9778 | Val loss 1.6275 acc 0.6172\n",
      "Epoch 19/20 | Train loss 0.0713 acc 0.9786 | Val loss 1.6795 acc 0.6254\n",
      "Epoch 20/20 | Train loss 0.0658 acc 0.9817 | Val loss 1.7278 acc 0.6177\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5bc47b6dd91a78e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a44efeaa17ec9190"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
