{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.035765Z",
     "start_time": "2025-12-21T18:11:19.024372Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch                          # Le cœur de PyTorch : tensors, calculs, GPU\n",
    "import torch.nn as nn                 # Contient toutes les couches du réseau (Conv2D, Linear, etc.)\n",
    "import torch.optim as optim           # Optimiseurs pour entraîner le modèle (Adam, SGD, etc.)\n",
    "from torch.utils.data import DataLoader  # Pour gérer le batching et le shuffle des datasets\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets, transforms, models  # Outils pour datasets, transformations et modèles pré-entraînés\n",
    "from torch import tensor\n",
    "\n",
    "import numpy as np                    # Manipulation de tableaux, conversion images → tensors\n",
    "import pandas as pd                   # Pour lire et écrire le fichier test_template.csv\n",
    "import os                             # Gestion des fichiers et dossiers\n",
    "\n",
    "# -----------------------------\n",
    "# Librairies pour la visualisation\n",
    "# -----------------------------\n",
    "import matplotlib.pyplot as plt       # Visualiser les images et tracer des courbes\n",
    "\n",
    "# -----------------------------\n",
    "# Librairies pour la vision par ordinateur\n",
    "# -----------------------------\n",
    "import cv2                            # Capturer la webcam et détecter les visages\n",
    "from PIL import Image \n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf8e8b82b9cec0fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.415221Z",
     "start_time": "2025-12-21T18:11:19.072187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'neutral')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions = ['neutral', 'angry', 'fear', 'happy', 'sad', 'surprise', 'disgust']\n",
    "emotion = 'neutral'\n",
    "x = random.randint(0, 6)\n",
    "path = f'data/dataTrain/train/{emotion}/'\n",
    "img = io.imread(os.path.join(path, random.choice(os.listdir(path))))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(emotion)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0c74cba097aa9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.532552Z",
     "start_time": "2025-12-21T18:11:19.433898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy : 7215\n",
      "sad : 4830\n",
      "fear : 4097\n",
      "surprise : 3171\n",
      "neutral : 4965\n",
      "angry : 3995\n",
      "disgust : 436\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for emotion in os.listdir('data/dataTrain/train'):\n",
    "    print(emotion, \":\", len(os.listdir(os.path.join('data/dataTrain/train', emotion))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8ee914af4626b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.760378Z",
     "start_time": "2025-12-21T18:11:19.653588Z"
    }
   },
   "outputs": [],
   "source": [
    "#Éviter le changement dans validation (on veut avoir les images réels)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    \n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomRotation(10),        # rotation ±10°\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),  # zoom léger\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225)\n",
    "    )\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"data/dataTrain/train\", transform=train_transform)\n",
    "val_data   = datasets.ImageFolder(\"data/dataTrain/train\", transform=val_transform)\n",
    "test_data  = datasets.ImageFolder(\"data/dataTest\", transform=val_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f799ac6eb5969f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.856250Z",
     "start_time": "2025-12-21T18:11:19.793274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split train / validation\n",
    "train_size = int(0.8 * len(train_data))\n",
    "validation_size = len(train_data) - train_size\n",
    "train_dataset, validation_dataset = random_split(train_data, [train_size, validation_size])\n",
    "\n",
    "# ⚠️ Remplacer le dataset de validation par celui sans augmentation\n",
    "validation_dataset.dataset = val_data\n",
    "\n",
    "# Créer les DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) # 128 trop aggressif au debut \n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=False)\n",
    "test_loader  = DataLoader(test_data, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14485ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aab4e647575f7bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:20.332715Z",
     "start_time": "2025-12-21T18:11:19.875120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=512, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/massylia/Desktop/HackatonCodeML-main/.venv/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/massylia/Desktop/HackatonCodeML-main/.venv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# --- Modèle : ResNet18 fine-tuning ---\n",
    "modeleEmotions = models.resnet18(pretrained=True)\n",
    "\n",
    "#degele aussi layer 3 (avant que 4) \n",
    "for name, param in modeleEmotions.named_parameters():\n",
    "    if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "nbEmotions = 7\n",
    "modeleEmotions.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(512, nbEmotions)\n",
    ")\n",
    "\n",
    "\n",
    "print(modeleEmotions) # Modèle de classification des émotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154f4b8c91daf5c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:25:20.794832Z",
     "start_time": "2025-12-21T18:25:20.701385Z"
    }
   },
   "outputs": [],
   "source": [
    "#loss function on ne veut pas geler toutes les couches. Sinon, le modele s'ameliore trop lentement\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "modeleEmotions = modeleEmotions.to(device)\n",
    "\n",
    "# --- Optimiseur:recopies / recoles la ligne de l’optimizer juste après avoir changé requires_grad.\n",
    "# (pour que l’optimizeur reconnaisse les nouvelles couches )---\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, modeleEmotions.parameters()),\n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "# Scheduler qui réduit le learning rate. eviter stagnation \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',          # surveille la val_loss\n",
    "    factor=0.5,          # réduit LR de moitié\n",
    "    patience=1,          # attend 1 epoch avant de réduire\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b327164ef180ec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:25:27.575737Z",
     "start_time": "2025-12-21T18:25:22.846111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs shape: torch.Size([64, 7])\n",
      "labels shape: torch.Size([64])\n",
      "labels dtype: torch.int64\n",
      "labels min/max: 0 6\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "images, labels = next(iter(train_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "outputs = modeleEmotions(images)\n",
    "print(\"outputs shape:\", outputs.shape)   # doit être (64, 7) ou (dernier batch, 7)\n",
    "print(\"labels shape:\", labels.shape)     # doit être (64,) ou (dernier batch,)\n",
    "print(\"labels dtype:\", labels.dtype)     # doit être torch.int64 (Long)\n",
    "print(\"labels min/max:\", labels.min().item(), labels.max().item())  # doit être 0..6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529154f831b8c8a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T21:44:18.751042Z",
     "start_time": "2025-12-21T19:00:15.533475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train loss 1.3454 acc 0.4887 | Val loss 1.1025 acc 0.5873\n",
      "Epoch 2/10 | Train loss 1.0607 acc 0.6031 | Val loss 1.0120 acc 0.6186\n",
      "Epoch 3/10 | Train loss 0.9553 acc 0.6423 | Val loss 0.9908 acc 0.6444\n",
      "Epoch 4/10 | Train loss 0.8899 acc 0.6690 | Val loss 0.9887 acc 0.6425\n",
      "Epoch 5/10 | Train loss 0.8143 acc 0.6998 | Val loss 0.9778 acc 0.6444\n",
      "Epoch 6/10 | Train loss 0.7528 acc 0.7222 | Val loss 0.9691 acc 0.6573\n",
      "Epoch 7/10 | Train loss 0.7009 acc 0.7396 | Val loss 0.9961 acc 0.6545\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# --- Boucle principale ---\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     train_loss, train_acc = \u001b[43mrun_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodeleEmotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     val_loss, val_acc = run_one_epoch(modeleEmotions, validation_loader, training=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     41\u001b[39m     scheduler.step(val_loss) \u001b[38;5;66;03m#éviter stagnation\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mrun_one_epoch\u001b[39m\u001b[34m(model, loader, training)\u001b[39m\n\u001b[32m     25\u001b[39m     loss.backward()\n\u001b[32m     26\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * images.size(\u001b[32m0\u001b[39m)\n\u001b[32m     29\u001b[39m preds = outputs.argmax(dim=\u001b[32m1\u001b[39m)\n\u001b[32m     30\u001b[39m correct += (preds == labels).sum().item()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "def run_one_epoch(model, loader, training: bool):\n",
    "    if training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.set_grad_enabled(training):\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            if training:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)              # (batch, nbEmotions)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if training:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "# --- Boucle principale ---\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = run_one_epoch(modeleEmotions, train_loader, training=True)\n",
    "    val_loss, val_acc = run_one_epoch(modeleEmotions, validation_loader, training=False)\n",
    "\n",
    "    scheduler.step(val_loss) #éviter stagnation (déplacé car il doit voir la loss value a chaque epoch pour s'ajuster)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train loss {train_loss:.4f} acc {train_acc:.4f} | \"\n",
    "          f\"Val loss {val_loss:.4f} acc {val_acc:.4f}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
