{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.035765Z",
     "start_time": "2025-12-21T18:11:19.024372Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch                          # Le cœur de PyTorch : tensors, calculs, GPU\n",
    "import torch.nn as nn                 # Contient toutes les couches du réseau (Conv2D, Linear, etc.)\n",
    "import torch.optim as optim           # Optimiseurs pour entraîner le modèle (Adam, SGD, etc.)\n",
    "from torch.utils.data import DataLoader  # Pour gérer le batching et le shuffle des datasets\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets, transforms, models  # Outils pour datasets, transformations et modèles pré-entraînés\n",
    "\n",
    "\n",
    "import numpy as np                    # Manipulation de tableaux, conversion images → tensors\n",
    "import pandas as pd                   # Pour lire et écrire le fichier test_template.csv\n",
    "import os                             # Gestion des fichiers et dossiers\n",
    "\n",
    "# -----------------------------\n",
    "# Librairies pour la visualisation\n",
    "# -----------------------------\n",
    "import matplotlib.pyplot as plt       # Visualiser les images et tracer des courbes\n",
    "\n",
    "# -----------------------------\n",
    "# Librairies pour la vision par ordinateur\n",
    "# -----------------------------\n",
    "import cv2                            # Capturer la webcam et détecter les visages\n",
    "from PIL import Image \n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf8e8b82b9cec0fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.415221Z",
     "start_time": "2025-12-21T18:11:19.072187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'neutral')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions = ['neutral', 'angry', 'fear', 'happy', 'sad', 'surprise', 'disgust']\n",
    "emotion = 'neutral'\n",
    "x = random.randint(0, 6)\n",
    "path = f'data/dataTrain/train/{emotion}/'\n",
    "img = io.imread(os.path.join(path, random.choice(os.listdir(path))))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(emotion)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0c74cba097aa9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.532552Z",
     "start_time": "2025-12-21T18:11:19.433898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy : 7215\n",
      "sad : 4830\n",
      "fear : 4097\n",
      "surprise : 3171\n",
      "neutral : 4965\n",
      "angry : 3995\n",
      "disgust : 436\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for emotion in os.listdir('data/dataTrain/train'):\n",
    "    print(emotion, \":\", len(os.listdir(os.path.join('data/dataTrain/train', emotion))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8ee914af4626b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.760378Z",
     "start_time": "2025-12-21T18:11:19.653588Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels = 3),            # images en niveaux de gris\n",
    "    transforms.Resize((224, 224)), # redimensionne à 48x48\n",
    "\n",
    "# data augmentation. eviter apprendre par coeur (chaque epoch change les images pour paraitre différement pour le modele)\n",
    "    transforms.RandomHorizontalFlip(),           # augmentation horizontale\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    \n",
    "    \n",
    "\n",
    "          \n",
    "    transforms.ToTensor(),             # convertit en tenseur [0,1]\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225)) # normalise entre -1 et 1\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"data/dataTrain/train\", transform=transform)\n",
    "test_data  = datasets.ImageFolder(\"data/dataTest\",  transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f799ac6eb5969f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.856250Z",
     "start_time": "2025-12-21T18:11:19.793274Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = int (0.8 * len(train_data))\n",
    "validation_size = len(train_data) - train_size\n",
    "train_dataset, validation_dataset = random_split(train_data, [train_size, validation_size])\n",
    "test_loader  = DataLoader(test_data, batch_size=128, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=128, shuffle=True) #batch size 128 plus rapide \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aab4e647575f7bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:20.332715Z",
     "start_time": "2025-12-21T18:11:19.875120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=512, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/massylia/Desktop/HackatonCodeML-main/.venv/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/massylia/Desktop/HackatonCodeML-main/.venv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# --- Modèle : ResNet18 fine-tuning ---\n",
    "modeleEmotions = models.resnet18(pretrained=True)\n",
    "\n",
    "#degele aussi layer 3 (avant que 4) \n",
    "for name, param in modeleEmotions.named_parameters():\n",
    "    if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "nbEmotions = 7\n",
    "modeleEmotions.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(512, nbEmotions)\n",
    ")\n",
    "\n",
    "\n",
    "print(modeleEmotions) # Modèle de classification des émotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154f4b8c91daf5c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:25:20.794832Z",
     "start_time": "2025-12-21T18:25:20.701385Z"
    }
   },
   "outputs": [],
   "source": [
    "#loss function on ne veut pas geler toutes les couches. Sinon, le modele s'ameliore trop lentement\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "modeleEmotions = modeleEmotions.to(device)\n",
    "\n",
    "# --- Optimiseur:recopies / recoles la ligne de l’optimizer juste après avoir changé requires_grad.\n",
    "# (pour que l’optimizeur reconnaisse les nouvelles couches )---\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, modeleEmotions.parameters()),\n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "# Scheduler qui réduit le learning rate. eviter stagnation \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',          # surveille la val_loss\n",
    "    factor=0.5,          # réduit LR de moitié\n",
    "    patience=1,          # attend 1 epoch avant de réduire\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b327164ef180ec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:25:27.575737Z",
     "start_time": "2025-12-21T18:25:22.846111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs shape: torch.Size([128, 7])\n",
      "labels shape: torch.Size([128])\n",
      "labels dtype: torch.int64\n",
      "labels min/max: 0 6\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "images, labels = next(iter(train_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "outputs = modeleEmotions(images)\n",
    "print(\"outputs shape:\", outputs.shape)   # doit être (64, 7) ou (dernier batch, 7)\n",
    "print(\"labels shape:\", labels.shape)     # doit être (64,) ou (dernier batch,)\n",
    "print(\"labels dtype:\", labels.dtype)     # doit être torch.int64 (Long)\n",
    "print(\"labels min/max:\", labels.min().item(), labels.max().item())  # doit être 0..6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529154f831b8c8a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T21:44:18.751042Z",
     "start_time": "2025-12-21T19:00:15.533475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train loss 1.3832 acc 0.4749 | Val loss 1.0639 acc 0.6029\n",
      "Epoch 2/20 | Train loss 1.0366 acc 0.6119 | Val loss 1.0022 acc 0.6264\n",
      "Epoch 3/20 | Train loss 0.8920 acc 0.6684 | Val loss 1.0060 acc 0.6404\n",
      "Epoch 4/20 | Train loss 0.7530 acc 0.7227 | Val loss 0.9922 acc 0.6449\n",
      "Epoch 5/20 | Train loss 0.6305 acc 0.7755 | Val loss 1.0213 acc 0.6421\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# --- Boucle principale ---\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     train_loss, train_acc = \u001b[43mrun_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodeleEmotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     val_loss, val_acc = run_one_epoch(modeleEmotions, validation_loader, training=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m acc \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     43\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVal loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m acc \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mrun_one_epoch\u001b[39m\u001b[34m(model, loader, training)\u001b[39m\n\u001b[32m     25\u001b[39m     loss.backward()\n\u001b[32m     26\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * images.size(\u001b[32m0\u001b[39m)\n\u001b[32m     29\u001b[39m preds = outputs.argmax(dim=\u001b[32m1\u001b[39m)\n\u001b[32m     30\u001b[39m correct += (preds == labels).sum().item()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "def run_one_epoch(model, loader, training: bool):\n",
    "    if training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.set_grad_enabled(training):\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            if training:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)              # (batch, nbEmotions)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if training:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "# --- Boucle principale ---\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = run_one_epoch(modeleEmotions, train_loader, training=True)\n",
    "    val_loss, val_acc = run_one_epoch(modeleEmotions, validation_loader, training=False)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train loss {train_loss:.4f} acc {train_acc:.4f} | \"\n",
    "          f\"Val loss {val_loss:.4f} acc {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a5835856f78ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece0b399baaf338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrainement\n",
    "# run_one_epoch(modeleEmotions, test_loader, training=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
