{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T03:56:34.133476500Z",
     "start_time": "2025-12-27T03:56:34.037725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch                          # Le cœur de PyTorch : tensors, calculs, GPU\n",
    "import torch.nn as nn                 # Contient toutes les couches du réseau (Conv2D, Linear, etc.)\n",
    "import torch.optim as optim           # Optimiseurs pour entraîner le modèle (Adam, SGD, etc.)\n",
    "from torch.utils.data import DataLoader  # Pour gérer le batching et le shuffle des datasets\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets, transforms, models  # Outils pour datasets, transformations et modèles pré-entraînés\n",
    "\n",
    "\n",
    "import numpy as np                    # Manipulation de tableaux, conversion images → tensors\n",
    "import pandas as pd                   # Pour lire et écrire le fichier test_template.csv\n",
    "import os                             # Gestion des fichiers et dossiers\n",
    "\n",
    "# -----------------------------\n",
    "# Librairies pour la visualisation\n",
    "# -----------------------------\n",
    "import matplotlib.pyplot as plt       # Visualiser les images et tracer des courbes\n",
    "\n",
    "# -----------------------------\n",
    "# Librairies pour la vision par ordinateur\n",
    "# -----------------------------\n",
    "import cv2                            # Capturer la webcam et détecter les visages\n",
    "from PIL import Image \n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random"
   ],
   "id": "aeb6b9ecbc34dcd5",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T03:56:34.469748300Z",
     "start_time": "2025-12-27T03:56:34.164568400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#observations des images\n",
    "emotions = ['neutral', 'angry', 'fear', 'happy', 'sad', 'surprise', 'disgust']\n",
    "emotion = 'neutral'\n",
    "x = random.randint(0, 6)\n",
    "path = f'data/dataTrain/train/{emotion}/'\n",
    "img = io.imread(os.path.join(path, random.choice(os.listdir(path))))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(emotion)\n",
    "# plt.show()"
   ],
   "id": "7514b82e2992d93f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'neutral')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T03:56:34.542961800Z",
     "start_time": "2025-12-27T03:56:34.483649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "for emotion in os.listdir('data/dataTrain/train'):\n",
    "    print(emotion, \":\", len(os.listdir(os.path.join('data/dataTrain/train', emotion))))\n"
   ],
   "id": "e36a18a5ab11cb4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry : 3995\n",
      "disgust : 436\n",
      "fear : 4097\n",
      "happy : 7215\n",
      "neutral : 4965\n",
      "sad : 4830\n",
      "surprise : 3171\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T03:56:34.564178Z",
     "start_time": "2025-12-27T03:56:34.546113900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels = 3), # images en niveaux de gris rgb\n",
    "    transforms.Resize((224, 224)),\n",
    "\n",
    "# data augmentation. eviter apprendre par coeur (chaque epoch change les images pour paraitre différement pour le modele)\n",
    "    transforms.RandomHorizontalFlip(),           # augmentation horizontale\n",
    "    transforms.ColorJitter(brightness=0.8, contrast=0.8),\n",
    "\n",
    "    transforms.ToTensor(),             # convertit en tenseur [0,1]\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225)) # normalise entre des range que imagenet comprend bien\n",
    "])\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels = 3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225))\n",
    "])\n"
   ],
   "id": "37ff90f6fdca3e4e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T03:56:34.890752900Z",
     "start_time": "2025-12-27T03:56:34.567685800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#80% des données d'entrainement pour l'entrainement et 20% pour validation\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "train_root = \"data/dataTrain/train\"\n",
    "\n",
    "# dataset \"base\" juste pour récupérer les labels (targets)\n",
    "base_ds = datasets.ImageFolder(train_root, transform=None)\n",
    "y = base_ds.targets  # liste d'entiers 0..6\n",
    "\n",
    "# séparation équilibré entre train et val\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(sss.split(X=[0]*len(y), y=y))\n",
    "\n",
    "# datasets avec les bons transforms\n",
    "train_full = datasets.ImageFolder(train_root, transform=train_transform)\n",
    "val_full   = datasets.ImageFolder(train_root, transform=eval_transform)\n",
    "\n",
    "train_dataset = Subset(train_full, train_idx)\n",
    "val_dataset   = Subset(val_full, val_idx)\n",
    "\n",
    "print(\"Train size:\", len(train_dataset), \"Val size:\", len(val_dataset))"
   ],
   "id": "e4e50d7a759bb228",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 22967 Val size: 5742\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T03:56:35.002160500Z",
     "start_time": "2025-12-27T03:56:34.901115700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# compter les classes dans le train split\n",
    "train_targets = [y[i] for i in train_idx]  # labels du train\n",
    "\n",
    "#compte le nombre d'images par class\n",
    "class_counts = torch.bincount(torch.tensor(train_targets))\n",
    "class_weights = 1.0 / class_counts.float() #attribut une proba a chaque class\n",
    "\n",
    "# poids par exemple (chaque image reçoit le poids de sa classe)\n",
    "sample_weights = torch.tensor([class_weights[t] for t in train_targets], dtype=torch.float)\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True #autorise de réutiliser des images\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler, num_workers=2, pin_memory=True)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
    "# test_loader  = DataLoader(test_data, batch_size=128, shuffle=False)"
   ],
   "id": "13a67a1fc4cf2655",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T03:56:35.306070400Z",
     "start_time": "2025-12-27T03:56:35.005161300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Modèle : ResNet18 fine-tuning ---\n",
    "modeleEmotions = models.resnet18(pretrained=True)\n",
    "\n",
    "# Dé-geler uniquement le dernier bloc convolutionnel + fc\n",
    "for name, param in modeleEmotions.named_parameters():\n",
    "    if \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "nbEmotions = 7\n",
    "modeleEmotions.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(512, nbEmotions)\n",
    ")\n",
    "\n",
    "\n",
    "print(modeleEmotions) # Modèle de classification des émotions\n"
   ],
   "id": "805228ee506d7176",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamta\\PycharmProjects\\PythonProject\\HackatonCodeML\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kamta\\PycharmProjects\\PythonProject\\HackatonCodeML\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=512, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T03:56:35.376397600Z",
     "start_time": "2025-12-27T03:56:35.309998400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#loss function on ne veut pas geler toutes les couches. Sinon, le modele s'ameliore trop lentement\n",
    "def get_device():\n",
    "    # NVIDIA GPU (Windows/Linux, parfois Mac via eGPU mais rare)\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    # Apple Silicon (Mac M1/M2/M3)\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    # Fallback\n",
    "    return torch.device(\"cpu\")\n",
    "print(torch.__version__)\n",
    "device = get_device()\n",
    "print(\"Using device:\", device)\n",
    "modeleEmotions = modeleEmotions.to(device)\n",
    "\n",
    "# --- Optimiseur et scheduler ---\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, modeleEmotions.parameters()),\n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "# Scheduler qui réduit le learning rate. eviter stagnation\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',          # surveille la val_loss\n",
    "    factor=0.5,          # réduit LR de moitié\n",
    "    patience=1,          # attend 1 epoch avant de réduire\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "2a63d1f1a27beeae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T03:56:45.348829400Z",
     "start_time": "2025-12-27T03:56:35.380026700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#sanity check\n",
    "images, labels = next(iter(train_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "outputs = modeleEmotions(images)\n",
    "print(\"outputs shape:\", outputs.shape)\n",
    "print(\"labels shape:\", labels.shape)\n",
    "print(\"labels dtype:\", labels.dtype)\n",
    "print(\"labels min/max:\", labels.min().item(), labels.max().item())  # doit être 0..6"
   ],
   "id": "4fd40c5040dab02b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs shape: torch.Size([64, 7])\n",
      "labels shape: torch.Size([64])\n",
      "labels dtype: torch.int64\n",
      "labels min/max: 0 6\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-27T03:56:45.410920700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 20 # 20 epoch de base pour chaque modification\n",
    "\n",
    "#fonction principace d'entraiment et de validation\n",
    "def run_one_epoch(model, loader, training: bool):\n",
    "    if training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.set_grad_enabled(training):\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            if training:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)              # (batch, nbEmotions)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            if training:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "# --- Boucle principale ---\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = run_one_epoch(modeleEmotions, train_loader, training=True)\n",
    "    val_loss, val_acc = run_one_epoch(modeleEmotions, validation_loader, training=False)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train loss {train_loss:.4f} acc {train_acc:.4f} | \"\n",
    "          f\"Val loss {val_loss:.4f} acc {val_acc:.4f}\")\n",
    "\n"
   ],
   "id": "a10c848ec8acb4c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train loss 1.5543 acc 0.4122 | Val loss 1.2237 acc 0.5387\n",
      "Epoch 2/20 | Train loss 1.2086 acc 0.5455 | Val loss 1.1249 acc 0.5829\n",
      "Epoch 3/20 | Train loss 1.0641 acc 0.5995 | Val loss 1.0951 acc 0.5949\n",
      "Epoch 4/20 | Train loss 0.9803 acc 0.6309 | Val loss 1.0616 acc 0.6108\n",
      "Epoch 5/20 | Train loss 0.9173 acc 0.6574 | Val loss 1.0850 acc 0.6047\n",
      "Epoch 6/20 | Train loss 0.8621 acc 0.6778 | Val loss 1.0496 acc 0.6142\n",
      "Epoch 7/20 | Train loss 0.8255 acc 0.6927 | Val loss 1.0719 acc 0.6130\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5bc47b6dd91a78e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a44efeaa17ec9190"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
