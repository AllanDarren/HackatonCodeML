{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.035765Z",
     "start_time": "2025-12-21T18:11:19.024372Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch                          # Le cœur de PyTorch : tensors, calculs, GPU\n",
    "import torch.nn as nn                 # Contient toutes les couches du réseau (Conv2D, Linear, etc.)\n",
    "import torch.optim as optim           # Optimiseurs pour entraîner le modèle (Adam, SGD, etc.)\n",
    "from torch.utils.data import DataLoader  # Pour gérer le batching et le shuffle des datasets\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets, transforms, models  # Outils pour datasets, transformations et modèles pré-entraînés\n",
    "\n",
    "\n",
    "import numpy as np                    # Manipulation de tableaux, conversion images → tensors\n",
    "import pandas as pd                   # Pour lire et écrire le fichier test_template.csv\n",
    "import os                             # Gestion des fichiers et dossiers\n",
    "\n",
    "# -----------------------------\n",
    "# Librairies pour la visualisation\n",
    "# -----------------------------\n",
    "import matplotlib.pyplot as plt       # Visualiser les images et tracer des courbes\n",
    "\n",
    "# -----------------------------\n",
    "# Librairies pour la vision par ordinateur\n",
    "# -----------------------------\n",
    "import cv2                            # Capturer la webcam et détecter les visages\n",
    "from PIL import Image \n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf8e8b82b9cec0fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.415221Z",
     "start_time": "2025-12-21T18:11:19.072187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'neutral')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAM05JREFUeJzt3QtwFeX5x/FX5WIIkJAACXcQUECrVgSk7V+totRRq8WZ2k47pdXWatGKTKeWTrU3Hay2XoviVAu9WTq0xeto66DgOCVUsYx4Q1GQIBCugQgEFc5/3m2TJsA+v5N9k74H8v3MnFHyZs/Zs/vuebJ7nmefI3K5XM4BAPA/duT/+gUBACAAAQCi4QwIABAFAQgAEAUBCAAQBQEIABAFAQgAEAUBCAAQBQEIABAFAQg4jH31q191gwcPjr0awEERgICI1q1b5370ox+5ZcuWsR/Q7hCAgMgB6Mc//jEBCO0SAQg4hOzatSv2KgCthgAEOJdcBjviiCPcypUrk+9NSktLXUlJifva1752wIf+73//ezd69GhXVFTkysrK3Be+8AVXXV3d7Hf89y7+efZ35plnJg9v4cKFbsyYMcn/+9fxr+8fc+bMafzdE044wS1dutSdfvrprkuXLu773/9+MvbII4+4888/3/Xt29d17tzZDR061P30pz91e/fuZX/ikNEh9goAheTzn/+8GzJkiJsxY4Z76aWX3AMPPOB69+7tfvaznyXjN998s7vhhhuS3/v617/uNm3a5O65554kQPzrX/9KAle+Ro4c6X7yk5+4G2+80V1xxRXu//7v/5Kff+ITn2j8nS1btrjzzjsvCXJf/vKXXUVFRfJzH6S6du3qpk2blvz3mWeeSZ5nx44d7rbbbmv17QK0Cd8PCGjvfvjDH/q+WLnLLrus2c8/97nP5crLy5P/X716de6oo47K3Xzzzc1+Z/ny5bkOHTo0+/mgQYNykydPPuB1zjjjjOTR4IUXXkhed/bs2Qf9XT82a9asA8Z27dp1wM+++c1v5rp06ZKrr69v/JlfB78uQCHiEhzQxJVXXtlse/izEn8W4s8s/vrXv7p9+/YlZz+bN29ufFRWVrrhw4e7Z599ttW3pb+85i/P7c9f/mtQV1eXrIdfV3+58I033mCf4pDAJTigiYEDBzbbHj169Ej+u23bNvfWW2/5KwZJsDmYjh07tvq27Nevn+vUqdMBP3/11VfdD37wg+TSmw+OTW3fvr3V1wNoCwQgoImjjjrqoNvDBx5/9uOTBJ588smD/p7/LqaB/72D8UkCaa9xME3PdBrU1ta6M844w3Xv3j35DsknIBx99NHJd1bXX399sp7AoYAABOTJf9D7QOSTFI499ljzd/2Zkw8U+3v33XfdMcccIwOVxWfP+cuC/pKgT35osGrVqhY/FxAT3wEBeZo0aVJy9uILR30gasr/2weFpsGqqqrKffDBB40/e/zxxw9I1y4uLk7+e7BglabhDKrpOvjXuffee9mXOKRwBgTkyQeVm266yU2fPt2tXr3aXXzxxa5bt27Jmcf8+fOTVOrvfOc7ye/6FO0///nP7jOf+UyStPD2228n9UP+OfZ/Tp+6PWvWrOS5fEAaN25ccpaVxqdp+zOsyZMnu29/+9vJWdTvfve7A4IiUOg4AwJa4Hvf+577y1/+4o488sjkTMgHnEcffdSde+657rOf/Wzj702cONH94he/cG+++aabOnWqW7x4cXIG1L9//wMSF37zm98kZzU+A++LX/yiW7RokbkO5eXlyXP16dMnSUT4+c9/7s455xx36623si9xSDnC52LHXgkAQPvDGRAAIAoCEAAgCgIQACAKAhAAIAoCEAAgCgIQACCKgitE9fex8m2KfVFeltuUAADi8tU9/i7tvmGir5mzfrFN/PKXv0z6kHTu3Dk3duzY3JIlS/Jarrq6OumBwoNtwBxgDjAH3CG9DfznuaVNzoD+9Kc/JZ0a/e1F/G1F7rzzzqQyfMWKFUl3SYs/82loaZwWOfdvkdzU/pXm+1P33PJnXxbrtX3LZIvqltnw3g9m/1u4qDYC+7Nu7eL72Vh8xb3Ft662hLQpOFgrgqY6dOiQaSyf527JXatbSm0T669GdWVA1ZaHjKs7bX/00Ucuqz179pjjviVG1mPXt6+wPPXUU+b4888/n/kYUNusV69emd93fX29uax59vGfflMWa92t1/ZzyH9WWp9pXpsEoNtvv9194xvfaGyk5QPRE0884X79618ntzKxNBxcfsOlbTxro6oPHfWhEnLZTy2rJoO1buoDS00kf7v+rIGz4YaZaZq2IWjtAKTeV0gAUs9NAPrfBiD1Yfrhhx9mnqfW/M9nroQc2yrgHyU+k0L+GAn9TAp57rxe37Uyf1fepUuXugkTJvz3RY48Mvm3vx/Wwf7q8Q21mj4AAIe/Vg9AvjWwb7pVUVHR7Of+3xs2bDjg92fMmJGcvjY8BgwY0NqrBAAoQNHTsP2t7X0L4YbH/v1SAACHp1b/Dqhnz57JNc2amppmP/f/PtiX3f46vLoWDwA4/LR6APKZRaNHj3YLFixIGnY1fHHp/3311Vfn/TxlZWWpXwz6bLo077//ftCXYjt37jTHrWCpMj66d+8u33Ma34BM9YixWMuHZOflk6RgbbOQbDA1HpJBl88X7v5Sc5b18mLWuIV+cR3yhbq1zdT+UnPcWm/1uTBq1Chz3Pd1shzs64UG6g/sLU066bY0iaFpx90sCUIqacQ6BqysxXy7/LRJFpxPwfbdGk899VQ3duzYJA3bf7A3ZMUBANAmAejSSy91mzZtcjfeeGPyl8HJJ5+c5Nnvn5gAAGi/2uxWPP5yW0suuQEA2pfoWXAAgPaJAAQAiIIABACIouDaMTRN8UtLETzuuOMyp9auWrUqaL2sVFF1vymVzmzdlFClYavnDqm1UqmeKpXT2i6h9+Zry3tZtfV9srLKN8W1LdY9ZJuo/W2laOfz2tYx0K9fP3PZU045xRxfvXq1Of7ss89mfl/14h541rjaJlu3bjXH1fLWulsp3n6O5nNfQM6AAABREIAAAFEQgAAAURCAAABREIAAAFEQgAAAURCAAABRFGwdkO+Mmnarfuumpo8++mhQXry6Jbw1rmqQVK2Odbv5Ll26tNlt8FWdgmpLoOpSrLoStWxInZCqQ1CvrVpFWOumtllbCtkfajy0lYO1bqE1Rla9mWqFMnjwYHPc39XfYjXSVK0cOosavbq6uszvS+0P9XlnzWNrf+Vbq8YZEAAgCgIQACAKAhAAIAoCEACAAAQAaD84AwIAREEAAgBEUbB1QL7XRFodxmuvvZa63Pbt24N624TU26g6hqKiosyvrWoF1HpbvTtULYHqc6TqiHbt2pVpvfLZptb+UDUQqlZHjYfMhbbs6RPa5yikDkix5oqqo1P7w6rbUvVk6vgZMWKEOX7yySenjr399tuZjw+vd+/eLs2HH37oLMOGDTPH33//fXN87dq1qWN9+vQx95VVv9SAMyAAQBQEIABAFAQgAEAUBCAAQBQEIABAFAQgAEAUBCAAQBQFWwe0Z8+e1Lz/+vr61OV2794d9LqqzsGqF1B1PqrOwar1UXVAatyqO/HbOmSbqDogq+5E7S9Vt2Vtc7U/FFV3Yr0vVXei6oBC6oRCe/a0ZR2Q2i4hrP2h5oKqR7Nqcbzhw4enjvXt29dc9k3RL8iqw+vXr5+5rOqJpeomS0tLM/U3U58JDTgDAgBEQQACAERBAAIAREEAAgBEQQACAERBAAIARFGwadj+NuBpKZsvv/xy5udVaaTq9ubWeFlZWVBbAyuNVC2rWioUFxdnTg9XqZwh42rZkHRk1XZAUeuWb6ppa7dEiJmGHVNIaruVMpzPvty5c2fmNO1evXqZy65cuTLzPFTH/ebNm83xioqKzO0aamtrM5cwNOAMCAAQBQEIABAFAQgAEAUBCAAQBQEIABAFAQgAEAUBCAAQRcHWAW3atCm1VsK6RX9oDUPHjh0z1wuo1gJWKwd1S3j1vlSdgjXeqVOnoG1i1RipmgBV26Het1X7oWoRQmqM1PKqhkht05h1Otb7UtsspMYodH9Zc1w9d+h4SUlJplYN3tKlS53Faj+zevXqoPomdexmXa98jy3OgAAAURCAAABREIAAAFEQgAAAURCAAABREIAAAFEQgAAAURRsHdDGjRsz1TuoPisqP13lzVvPX1RUJN+TZc2aNZlqhPLpOWL1/dizZ09Q/VKPHj3M8WHDhmWunQrpsaT2tarF6dy5c+beUKpuRM0zay6pZXft2hX02ladndpf6hiwesgo6vPAOr58f7GQff36669nrkFSx255ebk5vm7duszHbr9+/czx9evXZ54r1hh1QACAgsYlOABAFAQgAEAUBCAAQBQEIABAFAQgAEAUBZuG7dMLs6Rhq/RXlabdoYO9Sax1qq6uDkpBtdKCrTRqlaqp0jXVeqmWCSoNu2/fvpnTRMeMGWOODxo0qE3WK3SuWCna+cxTK6VYpQy/88475viGDRsyp7Y/99xz5rI7duwwx63U3bq6OnNZ9b6teWq1DsiH2l+bN2/OnBbfQXzmWK+t0rCt0o585qlVgmG1cfHrrOaCxxkQACAKAhAAIAoCEAAgCgIQACAKAhAAIAoCEAAgCgIQACCKgq0D8jUxaTU3IbfBV7UdannrdvTWbezzydkvLi7OfNt09doh661s27bNHN+0aVPm+qU33njDHD/55JNTxz72sY+Zy6pbxldWVmaeS6qGTY1bdSvW9lQ1KfnUfVVVVaWOvfLKK0E1Rla7BtXqQW0zq06oW7dumZfNh1XDp+qAPhS1OFZ90/vvvx/UpkV9JqlanzT51nC2+AzIF6JdeOGFSRGff5GHH374gIP6xhtvdH369Ekm24QJE9xbb73V0pcBABzmWhyAfOOlk046yc2cOfOg47feequ7++673axZs9ySJUuSv+onTpwYXIkMAGjnl+DOO++85HEw/uznzjvvdD/4wQ/cRRddlPzst7/9bXIbGX+m9IUvfCF8jQEAh4VWTUJYtWpVcg3YX3ZrUFJS4saNG+cWL16ceg3S3zOo6QMAcPhr1QDU8AXk/jfO9P9O+3JyxowZSZBqeAwYMKA1VwkAUKCip2FPnz7dbd++vfGh7igNADg8tGoAakhbrampafZz/++0lFaf/ti9e/dmDwDA4a9V64CGDBmSBJoFCxY01mf473R8NtxVV13VoufyOeZpueSqVidrXns+rFoFfwkxa+8ar2fPnpl6tORT22HV+qg6IFVr4M9cs9YJqddW9RtWf5mPPvrIXLZr165B9RlWjya1v1SdhDXPVF2JmuOq9mrFihWZ62VUjyVr3VX/Jqs3jVdaWpo6pi7tq5ovVaNkHQNqe9cG9AlTVK8h9Qe/dXxa9Umqxi5zAPIfRitXrmyWeLBs2TJXVlbmBg4c6KZOnepuuukmN3z48CQg3XDDDcmkvPjii1v6UgCAw1iLA9CLL77oPv3pTzf+e9q0acl/J0+e7ObMmeO++93vJrVCV1xxRRLZP/WpT7mnnnpK/kUIAGhfWhyAzjzzTPP0yl9a+MlPfpI8AAAo2Cw4AED7RAACAERBAAIARFGw7Rj8d0lpqapWCqtKb1XpgfneRjxLmmh5ebk57u8gnjVl2FpWpeaqtF6VZq3Slbds2ZL5uVUKqpUibqUT55Oiqt6XlTas5oKVwqqWr6ury7y985njPnEo6/5Q6cpWyxG1P1Qik5WSr1jrlU+atjWP1fFVZLSoUPtLveeNGzcGlTlYpQytUbPJGRAAIAoCEAAgCgIQACAKAhAAIAoCEAAgCgIQACAKAhAAIIqCrQPydStZ2jGoVg1qXNVnWONHHhkWz636DqulQT63ybfqn+rr64PqYdS6WW0qVO3H5s2bM9cpqGXfeOMNc3zw4MGZt6lqiaDet6ojCqnFUceA1RRStRZQdXZ79uzJvM1UzYrVHmPNmjXyJsshr221oVC1Oh0C6p/Uvlb7Q7VasWp9Qj/vkucIfgYAADIgAAEAoiAAAQCiIAABAKIgAAEAoiAAAQCiIAABAKIo2DogX3uSVgdk5dWrvHeVc6/GrXobVUOk6m2sGgmVr69e23pf6j0vWbLEHD/ttNPMcateQPUxUuv27rvvZt7eqh5G9dVpq34/apupZdX7UrU8Vj2a2qY7duwwx6uqqlLHRo4caS6r3rdVb6ZquoYMGWKOP//88+Z4bW2ty6pDwGeSWlbVIFl1dKqXkbWs+hxuwBkQACAKAhAAIAoCEAAgCgIQACAKAhAAIAoCEAAgCgIQACCKgq0D8nUQaXVAHTt2TF3ugw8+kM9rUXn1PXr0SB3r2rVrUG2IVWOk6i/U+7ZqdVQNg6oDUjVKVp+WKVOmmMs+8cQTmesUVD+grVu3muNqm1u1Dmpfq/qMtqr58nr16mWOb9++PXPNl5oLDz/8cOb1KioqMseHDh2auT5p2bJl5viAAQPM8U2bNmU+NhWrH5Cq+cq3HidLLzDruakDAgAUNC7BAQCiIAABAKIgAAEAoiAAAQCiIAABAKIo2DRsn4KdloatUqnb8jb5PXv2zHxLdytVU6U8btu2zVx21KhR5viIESMypwTX1NSY42vXrjXH+/fvn+kW+mp7qzRstT/U+wqZK2lzN9/ntpZXz63Sma1SAtWGwkqpzyddeezYsZlaNXjHH3+8OX7BBRdkTqlfs2ZNUMp+7969U8dWr15tLnuk+Dyz5opVkpJPCriaS221bAPOgAAAURCAAABREIAAAFEQgAAAURCAAABREIAAAFEQgAAAURyRC71fdyvzt033tSH+kZZnvnv37tTl9+zZYz5/WVlZ5nx+VU8zcuRIc1lVb2PVX6jWAqoWZ/jw4aljxx57bNA2s26Dr6j3pfbnypUrM415dXV15vhll11mjk+cODFTaw2vU6dOmWs/du7caS6rWg9Yt/dX+2TDhg1B+8uqx1F1JWoeWttU1Ripeahe26opW7duXVB94Ntvv506Vl1dbS5rfVaGstp++LDiP+98a4/u3bun/h5nQACAKAhAAIAoCEAAgCgIQACAKAhAAIAoCEAAgCgIQACAKAq2H1B5eXlqnwyVV29RtQaqfsPqv9G1a1dz2T59+mTu3aHy+VU/k/Xr16eOvfnmm0H9Y1Q9jbVdKisrzWVVmZq1P1RNilWfkE9vqH379rms1Puy5qlVf5FPnY8at3r+vP/++0E1LVYNU3FxsbnsO++8k7n+SW0z1U9Lsbap2t77xDx67733MvcDUseAmodWPZrVx6ihDkjhDAgAEAUBCAAQBQEIABAFAQgAEAUBCAAQBQEIABBFwaZh19bWmml+bZWGbaUdqtRdlUaq0np79uyZOlZUVGQue/zxx2dOUVWpmqGp61Yat5V6nk/rga1bt6aOhXYaUdvlo48+Sh1TKaiqHUPW183ntVXar5Xaq+aZalvgb8+fdV+rUoSBAwdmPvbUNrXWW6VaqzneWRw/1ueg+rwKKRVQrOMr32OPMyAAQBQEIABAFAQgAEAUBCAAQBQEIABAFAQgAEAUBCAAQBQFWwf04YcfptafhNQHqbx59dxWjYR6bjVutS1Qt5NXt2Xv1atXm9XLqFoDqwZJ3d5/8+bN5rhVY6Hql1Qtjhq3Xjv0Fvwh+0TNYfXc1lxT9TLWPAutCVPrba2bNQe9+vr6oG3q6xazHpsdxbg1l1QNkfrcUKzXto4vv6/Use216JN8xowZbsyYMa5bt26ud+/e7uKLL3YrVqw4YEdOmTIl6efjP1AvueQSV1NT05KXAQC0Ay0KQIsWLUqCS1VVlXv66aeTs5Rzzz23WQXzdddd5x577DE3b9685Pd987hJkya1xboDAA5hLTo/e+qpp5r9e86cOcmZ0NKlS93pp5+e3K7iwQcfdA899JA766yzkt+ZPXu2GzlyZBK0TjvttNZdewBA+0xCaLg/UsP9n3wg8mdFEyZMaPydESNGJPdoWrx4cer9tvz12aYPAMDhL3MA8l+iTp061X3yk590J5xwQvKzDRs2JF/clpaWHtBj3o+lfa9UUlLS+BgwYEDWVQIAtIcA5L8LeuWVV9zcuXODVmD69OnJmVTDo7q6Ouj5AACHhkw5eldffbV7/PHH3XPPPef69+/f+PPKysokldKnJDY9C/JZcH4sLY1QpRICANp5APK53ddcc42bP3++W7hwoRsyZEiz8dGjRyc57QsWLEjSrz2fpr1mzRo3fvz4Fq2YT+FOy72vq6tzWanaEMXqSaJqCRTVx8Wi+gVZNRTqdVXth+rjYvXVCen3o5ZX6231dspnrljPH1qDZD13W/c5UvVqIXUn/jvirMuqfkDW+1K1NmquqGPbWl69r87iD3CrFkfVJ6ljW80la39ZtWz5ztEOLb3s5jPcHnnkkaQWqOF7Hf/djf8A9P+9/PLL3bRp05LEBH+A+4Dlgw8ZcACAzAHovvvuS/575plnNvu5T7X+6le/mvz/HXfckURlfwbk/yKZOHGiu/fee1vyMgCAdqDFl+AUf7o4c+bM5AEAQBpuRgoAiIIABACIggAEAIiCAAQAiKJg+wH5vPu0WgorJ1/VX1h57aFUPxPVH6NLly6Za1bUa1vbRdUSqBoJlZxi1W+oe/+F1DGouRBSs6LqZdRrq/dl7U9VpxNa82K9ttWzKp96Gav+SdUnqXoZay7s2rUrqD9TSA8yVeu2V8wFay6FzgU1T60aJGu9/b5Q88zjDAgAEAUBCAAQBQEIABAFAQgAEAUBCAAQBQEIABBFwaZh+3TNtNRH6xb9bX17ciudU6UU798pdn9W2qK6Fb1Kj7XSMVUKt0qnVOnKVhqqSlFtaPueZbuo9VJtPVRasPX8Ia01VHptaPsMlXJspeaquWKl7ap1V8duSCq0SldW42ouWJ8LIWnWoen+oay5ZG2TfNsxcAYEAIiCAAQAiIIABACIggAEAIiCAAQAiIIABACIggAEAIjikGzHYNW0qNoPVccQUmOhanVULYF1K3t1K/qQlglqWfW+1PLWNlX7Sz23VXul6l1Caz+s51evreokrFYRoe0x1DFgtUxQ7yukBkntD3VsWttMrbdqlRLSakW1gqgXLSysbZpvvU3WOqKsbVz8euVTC8cZEAAgCgIQACAKAhAAIAoCEAAgCgIQACAKAhAAIAoCEAAgioKtA/J5+2k56FZOv1Uj5KncdJWzb42rmpaQeprQPkchtQRqXL0vq75DPXdtbW3m911UVGQuq7ZpW9VIqFobtb9C65vUXLFqXlQ9WlsKmafqPYeOW/tE1RDtE/szpN5MfSapY8Sah61Rn8QZEAAgCgIQACAKAhAAIAoCEAAgCgIQACAKAhAAIIqCTcP2t1ZPS2W1UlxV2qFKrVUpxda4uqW7ur3/zp07U8eOPvpoc9kuXbq4rFSaqEqpDGnHoPaHSqsfOnRo5lTo4uLioFRpa93Uc6v0Wau1gNofKg27a9eumee4em41F6z9HVJKoMbVsRfSKkWNq+feFVD6obaZOr7U54r12WA9t5+japt5nAEBAKIgAAEAoiAAAQCiIAABAKIgAAEAoiAAAQCiIAABAKIo2DqgysrK1JqDkpKS1OVWr15tPq+qDVF1RFZO/saNG81lS0tLM+fkh95i36orCa2dUuPWuql6GMXapmouqPoMtc2t5VU9mWprENKaQ9XLWHNB1RmpGiT1vqzaEDUX1PuyalbU/rBq8PKp8bM+F9R614t6Gev4VMe9oo59azykVq0BZ0AAgCgIQACAKAhAAIAoCEAAgCgIQACAKAhAAIAoCEAAgCgKtg6orq4utd5B1TFYVE5+SD2A6gHj31PWGgqr9im0r47qCaK2mapLscbVNqmurjbH161bl7nOR633X//618w1EiNHjjSXVdvcmgtqm5WVlQW9b2u7VVRUBPWWUvPUEtIvSNXaqJ486nPBGlfL7hKvbb1vVccT8lmplrc+U6gDAgAUNC7BAQCiIAABAKIgAAEAoiAAAQCiIAABAKIgAAEAoijYOiCf355Wr2DVKai8d9VzRI1bOf2q1mDLli3meFFRUerYjh07gtbbqlGy8vnzoWparNqpbdu2mcuqbWrVG6gaIlWTElKfsXTpUnPZ448/PvM2ffTRR81lVd3JuHHjzPELLrgg8zxTNUbW8qp2RNW8WDVIal+G1gFZy6s5/IGonbLqm1Stm/o8DOn1ZR3X1AEBAAoal+AAAFEQgAAAURCAAABREIAAAFEQgAAAURRsGrZP50xL6bRSHlWaqLqluxq3UiZra2vNZVW6c5cuXTLdnj+f9x1y63RrvfJJvbXSZ63U83zSY6105d69e5vLvvfee0Fp81Zqu0oZ7tevnzneo0eP1LFTTz3VXHb16tVB+3Po0KGZ57CVmhvaWkClM+/evTvzPLKWzWd5Kx1ava+9AW0mVBq1KpFQ+9P6XLHWy3+mqPfV4jOg++67z5144omue/fuyWP8+PHuySefbDZBpkyZ4srLy13Xrl3dJZdc4mpqalryEgCAdqJFAah///7ulltuSYrsXnzxRXfWWWe5iy66yL366qvJ+HXXXecee+wxN2/ePLdo0aKkWdikSZPaat0BAO3lEtyFF17Y7N8333xzclZUVVWVBKcHH3zQPfTQQ0lg8mbPnp10hvTjp512WuuuOQCgfSYh+Ot7c+fOTW5R4S/F+bMif61zwoQJjb8zYsQIN3DgQLd48WLz2qm/zUzTBwDg8NfiALR8+fLk+x3/pfiVV17p5s+f70aNGuU2bNjgOnXq5EpLSw/oIe/H0syYMcOVlJQ0PgYMGJDtnQAADu8AdNxxx7lly5a5JUuWuKuuuspNnjzZvfbaa5lXYPr06W779u2ND3UDSQBAO03D9mc5w4YNS/5/9OjR7oUXXnB33XWXu/TSS5MUZZ+K3PQsyGfBVVZWpj6fP5NSKcYAgMNPcB2QzxP33+P4YORzyhcsWJCkX3srVqxwa9asSb4jain/XGn1JSH1Fyqf38ptb1ivrLUEat02btyYuV7G/2FgsYK8v6RqUbUG6n1b27Rbt27msh//+MfN8bVr12au4znmmGOCxve/3NyUupSsanmsdg2q5ssfc1nXW9UJqTofNVesuaDaEoSMq2XbslYnpN2CGldzQbVrUJ+HVo2ftc3ybcfQoaWXy84777wksaCuri7JeFu4cKH729/+lnx/c/nll7tp06a5srKypE7ommuuSYIPGXAAgKAA5P9C/8pXvuLWr1+fBBxflOqDzznnnJOM33HHHUnE9GdAPvJOnDjR3XvvvS15CQBAO9GiAOTrfNRtH2bOnJk8AACwcDNSAEAUBCAAQBQEIABAFAQgAEAUBdsPyNfbHHXUUS3OfVf5/Kr/hVreyqu36pPyqZexaii2bdtmLhtSJ6T6+aj+Mar2w6qhUHVAgwYNMsd9yn8adVcNtc3GjRsn7wqSRhVX+yzSrNtczaPBgweb42qbW313VE2Lqv+walrUsade2zpGQusDQ3oRqdqpPaJWJ2tPnnw+79I+Y/M5dq36QT8P8rmvJ2dAAIAoCEAAgCgIQACAKAhAAIAoCEAAgCgIQACAKAo2DdunRaalB1tpiSq1VqUGqpRkK+1RLatSPa10Zt/63OL7MGVNj1Wpmiq9XKXeWimsan+pbWqNqzYT/fr1M8dPOukkc9zqc2W1ichnLlj7RKV4h97+P2R/qNe23rdKV1bPbR0/6rj3d/e3qNR3azx0f+w0jn21rNpfqoTCShG3PofzbcfAGRAAIAoCEAAgCgIQACAKAhAAIAoCEAAgCgIQACAKAhAAIIqCrQM6/vjjU2shrNvsh9YpqNuuW7nvqlZH3QbfumW8qhtRdUDWepeWlgbdLj6krkRRdQrl5eWZWx6oOqBhw4Zlfu0OHexDS7WKsOahmkeqriukpYKq71D1Mtbt/duyxkgta61XPu/L2l/qufcEHF+qnYJ6bjVXrHH1vvLBGRAAIAoCEAAgCgIQACAKAhAAIAoCEAAgCgIQACAKAhAAIIqCrQPy/VTSctzXrVuXOa9d1WeoWgQrr171trHqfBRVB6Re26qDUH1YQnoNqW2q6hjUc1v7W9U3qTqgioqKzDVKqlbH6iWk5qnaZlbNl3puVdOinlvVhFm1I6quRD23td7q+Nm+fbs5rmr8rOMrtPZwr7FdQntDhRy71v6gHxAAoKBxCQ4AEAUBCAAQBQEIABAFAQgAEAUBCAAQRcGmYfu0ybQUwD59+qQut2XLlqDbk6s0U2tcpYl26tTJHLdSF1WqpkoTtdZbpfWqtN3i4uLMqdIqPVa9ry5dumR63XzmyqZNm8zxk046KXMriO7du2d+7ZqamqD0cZWyb81DNcfVNrfSerdu3Rp07Fopx2oeqVIEVZ5hHSPq2P1IbFOrfEN9pqhjU6VLW+se0rajAWdAAIAoCEAAgCgIQACAKAhAAIAoCEAAgCgIQACAKAhAAIAoCrYOyOf0p+Xe7969O3Pe+44dO4LXK8tYPvUX1u39VSsHVcdg1Rqo2g1Vq2Ott6olWL9+fVC9jFVvUFVVFfS+1Gv3798/dWzYsGHmsiHbXNUBqTYUw4cPN8dPPfXUzPUd27ZtyzwPreM6nxo9q05I1RCp40vV8tTV1bVZO4acsc1VfZKq8VPj1rFt7Q+/zuozyeMMCAAQBQEIABAFAQgAEAUBCAAQBQEIABAFAQgAEAUBCAAQRcHWAXXr1i01R/29995LXa5Hjx7m8w4dOtQcf+eddzLXC6haA1XnYOX0q/oLVVcSQtXLqBoKqxfLm2++aS6r+p1Y22zdunVB9RdWryFv+fLlqWNHH320uWyvXr2CesSE1Muo933sscemjvXt29dcVs3TAQMGZK67Un2prLoTNUdDt5l1bFs1Qvn0KrJqcdQ8UZ9JnTt3dlmpOqB8cAYEAIiCAAQAiIIABACIggAEAIiCAAQAiIIABACIggAEAIiiYOuAfB1FWh3QwIEDM9d+qPqM8vJyc3zv3r2Zaw1Uzr713EpInYPqV6Lql7p27WqOW/UdqnfN0qVLzfHa2trUsZEjR5rLlpSUmOOqlqFnz56ZeySpfX3MMcekjlVUVAQ9t6ppsWqzVL3MmDFjzHFru1j7Mp9eQ9Y8VXNYHT+qFm7Lli1tUuejevaozxT13Op9W9st31ofC2dAAIAoCEAAgCgIQACAKAhAAIAoCEAAgCgIQACAKAo2Dbt3796pt1+vrq7OlL6aT9sC6/b+3saNGzOnJar0V2vd1Hqp8R07dmR63XxSb1WKq5UWrNKwx44dmzmNVLVTULf/HzRokDk+bNiwzLe5t+aRSt0dNWqUC6HSnUePHp25PYaa41a7E1UOEDIP1bJWKweVZq1SxNX7OlIcu9bnivrMUftLtYqwSiysVg9+vfJpKRJ0BnTLLbckeeZTp05tNgGnTJmS1NP4lb/kkktcTU1NyMsAAA5DmQPQCy+84O6//3534oknNvv5dddd5x577DE3b948t2jRoqQwdNKkSa2xrgCA9h6A/Onql770JferX/2qWQfS7du3uwcffNDdfvvt7qyzzkpO5WfPnu3+8Y9/uKqqqtZcbwBAewxA/hLb+eef7yZMmHDAbVP8NfmmPx8xYkRy65zFixenXkf03080fQAADn8tTkKYO3eue+mll5JLcPvbsGFD8qXX/l8s+3tX+bGDmTFjhvvxj3/c0tUAALSnMyCffXbttde6P/zhD/KmnvmaPn16cumu4WFluAEA2mkA8pfYfProKaeckqRI+4dPNLj77ruT//dnOj7lcP80T58FV1lZmZqu6tNhmz4AAIe/Fl2CO/vss93y5cub/exrX/ta8j3P9ddf7wYMGJDUlCxYsCBJv/ZWrFjh1qxZ48aPH9+iFSsuLk6tT7HqM1RO/apVq4JqJMrKylLHNm3aZC5r5c2r266rfH51W3W/PbMuq+p8Qs6G165dG3QL/pDWGmp/qLlk3aK/qKgoaN2suhWrliaf9xXSukNtE1X/ZNXEqFod9b6s5dUcVvUwW7duzfy+VB1Qh5R6x3xqcVSrB0W1UrFq+FSrh1YPQN26dXMnnHDCAR9s/mBq+Pnll1/upk2blnxQ+7OZa665Jgk+p512WvDKAgAOH61+J4Q77rgj+SvJnwH5v1gmTpzo7r333tZ+GQBAew9ACxcuPOByzMyZM5MHAABpuBkpACAKAhAAIAoCEAAgCgIQACCKgu0H9Pbbb6fWxVj9a1StgFXHkw9/d++sefGqd4dVq6BqBRTruVWdguqVot63T9/PWlei6hSsdVc9XKx96W3evNkct2owVF2Jqp3q1atX6pgq1rbqyfLpk2SNq/2h+jtZx6eqaVG1PNb+VvVkof2A1LFt+Uj0zbHqzdQ2UaxjU9VWWZ/DfnuoejOPMyAAQBQEIABAFAQgAEAUBCAAQBQEIABAFAQgAEAUBZuGfeyxx6am+VkprqptgW96Z7FSC73BgwdnTr1Vab3Wuqk0UZVaa6VKqzRQlabdlu0a1Puy0n7VvlQp4Crdub6+PvP+Uimq1v5S70u1elCpt1bKv5oLqp2JlYatSijUa1up0FZbAc/3Ocv63CpdWbWZ6CBKLKz3rdLi1bEdcuyrZfPBGRAAIAoCEAAgCgIQACAKAhAAIAoCEAAgCgIQACAKAhAAIIqCrQN67733UvPjjznmmMy1NqompW/fvub4u+++mzrWv39/c9mePXua46+//nrq2I4dO8xl1a3srZoXtayqUyguLs58O3lVk6JaC3Tu3DlzHY967R49emQeV+ut6kqsWh9Vv6RqjEJu4R86D1XrjpCaMGvdVDsGVb+k6oisehxVE3aUmCtWfZSqCVO1VWoeWnPNqrmkHQMAoKBxCQ4AEAUBCAAQBQEIABAFAQgAEAUBCAAQBQEIABBFwdYB+VqFtPz4lStXZq79UDUUqkbCen6V76/6Z1i9hlSdwqZNm8xxa92sWpp8qDqgkG2i6hys/VFRUWEuW1JSkrnXkFdWVpa5Fkf1cVG1ISE1K6pWJ6QvVUjvJzUP169fb45btT7V1dXmsup9qblgzWM1F/aK/WVRz63qfNQ8s3oZWc+tXrcBZ0AAgCgIQACAKAhAAIAoCEAAgCgIQACAKAhAAIAoCEAAgCgKtg7I9/VJq9mxanlULYHKT1+3bl3mOofQWgKrP43q66Gee+vWralj9fX1QbVRIbVT5eXlQXVb1rjqH1NUVBTUB8mq/VDzzOqRpLaL2iYhPV7U8h988EFQvyCr5kUdP+q5V61alblPmJoLirU/1WfSXlEHZO0vtWxI/yU1F6zXpg4IAFDQuAQHAIiCAAQAiIIABACIggAEAIiCAAQAiKJg07B96m7arcKt9D91O3h1G3wrXVnd/rxnz57msh/72Mcyp4C/88475rIhrQdU6rlqBWHdBl9tc5XqrNKVrdRdlV6u5opq7WGlYav0V5U+a6W2qzRqdYt9dQt/a1y13lDvy9pmGzduNJetqakxx615rN6zSpVWbUGseZxvSnIMartY89iaZ/4959NmgjMgAEAUBCAAQBQEIABAFAQgAEAUBCAAQBQEIABAFAWXht2Qsmil8FljVppnPmmHKnUw63rlcydha9337duXeb3UuEoTDX1ta5urbaLGrbuEq7t0q9RblQJupUOrNGw1HvLcKg1b3Vl9586dmfe12mbWPlHrpY5da56qOR56DFjLh762pa1TvLO+r4YxtX5H5AosSX3t2rVuwIABsVcDABCourra9e/f/9AJQP4vDV9Q5nvj+L/0fA8QH5D8G1GFgfg3tlnLsc3YZv8L7WWe5XI5V1dX5/r27WuezRfcJTi/sgeLmH5nHc47rC2wzdhmzLPC1B6OzRLj7isNSEIAAERBAAIARFHwAchnKv3whz+UGUtgmzHP/rc4NtlmoQouCQEA0D4U/BkQAODwRAACAERBAAIAREEAAgBEQQACAERR8AFo5syZbvDgwe7oo49248aNc//85z9jr1LBeO6559yFF16Y3O7C37bo4YcfbjbuExxvvPFG16dPH1dUVOQmTJjg3nrrLddezZgxw40ZMya5zVPv3r3dxRdf7FasWNHsd+rr692UKVNceXm569q1q7vkkktcTU2Na8/uu+8+d+KJJzZW748fP949+eSTjeNsM9stt9ySHJ9Tp05lmx1KAehPf/qTmzZtWlIH9NJLL7mTTjrJTZw40W3cuDH2qhUEf9div018kD6YW2+91d19991u1qxZbsmSJa64uDjZfv4Doz1atGhRElyqqqrc008/ndxd+dxzz2129+frrrvOPfbYY27evHnJ7/v7Ek6aNMm1Z/7WWP5DdOnSpe7FF190Z511lrvooovcq6++moyzzdK98MIL7v77708CeFNss//IFbCxY8fmpkyZ0vjvvXv35vr27ZubMWNG1PUqRH5Xzp8/v/Hf+/bty1VWVuZuu+22xp/V1tbmOnfunPvjH/8YaS0Ly8aNG5PttmjRosbt07Fjx9y8efMaf+f1119Pfmfx4sUR17Tw9OjRI/fAAw+wzQx1dXW54cOH555++uncGWeckbv22muTnzPP/qtgz4B8Hxj/F5e/bNT0RqX+34sXL466boeCVatWuQ0bNjTbfv7mgP4yJtvv37Zv3578t6ysLPmvn2/+rKjpNhsxYoQbOHAg26xJP6C5c+cmZ43+UhzbLJ0/2z7//PObzSfmWYHfDbvB5s2bk8leUVHR7Of+32+88Ua09TpU+ODjHWz7NYy1Z77th78m/8lPftKdcMIJyc/8dunUqZMrLS1t9rtsM+eWL1+eBBx/+dZ/NzZ//nw3atQot2zZMrbZQfgg7b828Jfg9sc8OwQCENDWf52+8sor7vnnn2dD5+G4445Lgo0/a/zzn//sJk+enHxHhgP5Xj/XXntt8j2jT55CuoK9BNezZ8+ktfD+GUj+35WVldHW61DRsI3Yfge6+uqr3eOPP+6effbZZr2n/Dbzl35ra2ub/T5zziVnOcOGDXOjR49Osgl98stdd93FNjsIf1nSJ0qdcsoprkOHDsnDB2ufEOT/359RM88KPAD5Ce8n+4IFC5pdNvH/9pcCYBsyZEjy4dB0+/lujD4brr1uP5+r4YOPv3z0zDPPJNuoKT/fOnbs2Gyb+TTtNWvWtNttlsYfi3v27GGbHcTZZ5+dXLL0Z4wNj1NPPdV96Utfavx/5tl/5ArY3Llzk6ytOXPm5F577bXcFVdckSstLc1t2LAh9qoVTJbNv/71r+Thd+Xtt9+e/P+7776bjN9yyy3J9nrkkUdyL7/8cu6iiy7KDRkyJLd79+5ce3TVVVflSkpKcgsXLsytX7++8bFr167G37nyyitzAwcOzD3zzDO5F198MTd+/Pjk0Z5973vfSzIFV61alcwj/+8jjjgi9/e//z0ZZ5tpTbPg2Gb/VdAByLvnnnuSD4ROnToladlVVVWxV6lgPPvss0ng2f8xefLkxlTsG264IVdRUZEE8rPPPju3YsWKXHt1sG3lH7Nnz278HR+cv/WtbyVpxl26dMl97nOfS4JUe3bZZZflBg0alByDvXr1SuZRQ/Dx2GYtD0Bss3+jHxAAIIqC/Q4IAHB4IwABAKIgAAEAoiAAAQCiIAABAKIgAAEAoiAAAQCiIAABAKIgAAEACEAAgPaDMyAAgIvh/wEq2k8p+bWGzQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions = ['neutral', 'angry', 'fear', 'happy', 'sad', 'surprise', 'disgust']\n",
    "emotion = 'neutral'\n",
    "x = random.randint(0, 6)\n",
    "path = f'data/dataTrain/train/{emotion}/'\n",
    "img = io.imread(os.path.join(path, random.choice(os.listdir(path))))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(emotion)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0c74cba097aa9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.532552Z",
     "start_time": "2025-12-21T18:11:19.433898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy : 7215\n",
      "sad : 4830\n",
      "fear : 4097\n",
      "surprise : 3171\n",
      "neutral : 4965\n",
      "angry : 3995\n",
      "disgust : 436\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for emotion in os.listdir('data/dataTrain/train'):\n",
    "    print(emotion, \":\", len(os.listdir(os.path.join('data/dataTrain/train', emotion))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ee914af4626b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.760378Z",
     "start_time": "2025-12-21T18:11:19.653588Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels = 3),            # images en niveaux de gris\n",
    "    transforms.Resize((224, 224)), # redimensionne à 48x48\n",
    "\n",
    "# data augmentation. eviter apprendre par coeur (chaque epoch change les images pour paraitre différement pour le modele)\n",
    "    transforms.RandomHorizontalFlip(),           # augmentation horizontale\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    \n",
    "    \n",
    "\n",
    "          \n",
    "    transforms.ToTensor(),             # convertit en tenseur [0,1]\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225)) # normalise entre -1 et 1\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"data/dataTrain/train\", transform=transform)\n",
    "test_data  = datasets.ImageFolder(\"data/dataTest\",  transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f799ac6eb5969f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:19.856250Z",
     "start_time": "2025-12-21T18:11:19.793274Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = int (0.8 * len(train_data))\n",
    "validation_size = len(train_data) - train_size\n",
    "train_dataset, validation_dataset = random_split(train_data, [train_size, validation_size])\n",
    "test_loader  = DataLoader(test_data, batch_size=128, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=128, shuffle=True) #batch size 128 plus rapide \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aab4e647575f7bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:11:20.332715Z",
     "start_time": "2025-12-21T18:11:19.875120Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/massylia/Desktop/HackatonCodeML-main/.venv/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/massylia/Desktop/HackatonCodeML-main/.venv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=512, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# --- Modèle : ResNet18 fine-tuning ---\n",
    "modeleEmotions = models.resnet18(pretrained=True)\n",
    "\n",
    "# Dé-geler uniquement le dernier bloc convolutionnel + fc\n",
    "for name, param in modeleEmotions.named_parameters():\n",
    "    if \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "nbEmotions = 7\n",
    "modeleEmotions.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(512, nbEmotions)\n",
    ")\n",
    "\n",
    "\n",
    "print(modeleEmotions) # Modèle de classification des émotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154f4b8c91daf5c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:25:20.794832Z",
     "start_time": "2025-12-21T18:25:20.701385Z"
    }
   },
   "outputs": [],
   "source": [
    "#loss function on ne veut pas geler toutes les couches. Sinon, le modele s'ameliore trop lentement\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "modeleEmotions = modeleEmotions.to(device)\n",
    "\n",
    "# --- Optimiseur et scheduler ---\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, modeleEmotions.parameters()),\n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "# Scheduler qui réduit le learning rate. eviter stagnation \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',          # surveille la val_loss\n",
    "    factor=0.5,          # réduit LR de moitié\n",
    "    patience=1,          # attend 1 epoch avant de réduire\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b327164ef180ec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:25:27.575737Z",
     "start_time": "2025-12-21T18:25:22.846111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs shape: torch.Size([128, 7])\n",
      "labels shape: torch.Size([128])\n",
      "labels dtype: torch.int64\n",
      "labels min/max: 0 6\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "images, labels = next(iter(train_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "outputs = modeleEmotions(images)\n",
    "print(\"outputs shape:\", outputs.shape)   # doit être (64, 7) ou (dernier batch, 7)\n",
    "print(\"labels shape:\", labels.shape)     # doit être (64,) ou (dernier batch,)\n",
    "print(\"labels dtype:\", labels.dtype)     # doit être torch.int64 (Long)\n",
    "print(\"labels min/max:\", labels.min().item(), labels.max().item())  # doit être 0..6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529154f831b8c8a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T21:44:18.751042Z",
     "start_time": "2025-12-21T19:00:15.533475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train loss 1.4470 acc 0.4532 | Val loss 1.1898 acc 0.5552\n",
      "Epoch 2/20 | Train loss 1.1323 acc 0.5780 | Val loss 1.1096 acc 0.5885\n",
      "Epoch 3/20 | Train loss 0.9918 acc 0.6285 | Val loss 1.0840 acc 0.6034\n",
      "Epoch 4/20 | Train loss 0.8621 acc 0.6842 | Val loss 1.0779 acc 0.6090\n",
      "Epoch 5/20 | Train loss 0.7551 acc 0.7245 | Val loss 1.0880 acc 0.6221\n",
      "Epoch 6/20 | Train loss 0.6344 acc 0.7725 | Val loss 1.1218 acc 0.6174\n",
      "Epoch 7/20 | Train loss 0.5140 acc 0.8197 | Val loss 1.1720 acc 0.6101\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# --- Boucle principale ---\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     train_loss, train_acc = \u001b[43mrun_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodeleEmotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     val_loss, val_acc = run_one_epoch(modeleEmotions, validation_loader, training=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m acc \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     43\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVal loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m acc \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mrun_one_epoch\u001b[39m\u001b[34m(model, loader, training)\u001b[39m\n\u001b[32m     25\u001b[39m     loss.backward()\n\u001b[32m     26\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * images.size(\u001b[32m0\u001b[39m)\n\u001b[32m     29\u001b[39m preds = outputs.argmax(dim=\u001b[32m1\u001b[39m)\n\u001b[32m     30\u001b[39m correct += (preds == labels).sum().item()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "def run_one_epoch(model, loader, training: bool):\n",
    "    if training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.set_grad_enabled(training):\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            if training:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)              # (batch, nbEmotions)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if training:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "# --- Boucle principale ---\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = run_one_epoch(modeleEmotions, train_loader, training=True)\n",
    "    val_loss, val_acc = run_one_epoch(modeleEmotions, validation_loader, training=False)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train loss {train_loss:.4f} acc {train_acc:.4f} | \"\n",
    "          f\"Val loss {val_loss:.4f} acc {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a5835856f78ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece0b399baaf338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrainement\n",
    "# run_one_epoch(modeleEmotions, test_loader, training=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
